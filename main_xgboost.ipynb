{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-31T05:05:49.074345Z",
     "start_time": "2025-07-31T05:01:24.983991Z"
    }
   },
   "source": [
    "from src.graph_to_vec_converter import  HVs\n",
    "from sklearn.metrics       import accuracy_score, classification_report\n",
    "from sklearn.linear_model  import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from src.graph_generation import NMNISTGraphDataset\n",
    "from src.loader import ev_loader\n",
    "from src.graphcnnVSA_Binding_FULL import GraphCNN\n",
    "from src.codebook import CodeBook\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing   import StandardScaler\n",
    "from sklearn.svm             import SVC\n",
    "from sklearn.pipeline        import Pipeline\n",
    "from sklearn.metrics         import accuracy_score\n",
    "from torch.utils.data import ConcatDataset\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "print(\"[LOG] - parameter initialization.\")\n",
    "# GRAPH parameters\n",
    "DATA_NAME = \"SNKTH\" # NCARS, NMNIST\n",
    "DATA_PATH = \"data\"\n",
    "DATASET = \"full\"  # full / test      size of dataset loading for training and testing\n",
    "NORMALIZE_FEAT = False\n",
    "NUM_OF_GRAPH_EVENTS = 100  # None, 10, 50, 100. etc\n",
    "\n",
    "\n",
    "if DATA_NAME == \"SNKTH\":\n",
    "    X_MAX = 360\n",
    "    Y_MAX = 360\n",
    "    T_MAX = 1_000_000\n",
    "    T_STEP = 10_0\n",
    "\n",
    "    R = 2\n",
    "    D_MAX = 4\n",
    "\n",
    "    # NOISE parameters\n",
    "    NOICE_REMOVED = False\n",
    "    NR_BIN_XY_SIZE = 5\n",
    "    NR_TIME_BIN_SIZE = 20_00\n",
    "    NR_MINIMUM_EVENTS = 2\n",
    "\n",
    "\n",
    "\n",
    "# GVFA parameters\n",
    "# HV_DIMENTION = 5000\n",
    "LAYERS = 5\n",
    "DELTA = 1  # 2\n",
    "EQUATION = 11\n",
    "DEVICE = torch.device(\"cpu\")\n",
    "\n",
    "# load event streams\n",
    "print(\"[LOG] - Loading events\")\n",
    "# full_ev_ds = ev_loader(root=DATA_PATH, dataset=DATASET)\n",
    "ds = ev_loader(root=DATA_PATH, dataset=DATASET, data_name=DATA_NAME)\n",
    "ds_train, ds_test = train_test_split(ds, test_size=0.2, random_state=42,shuffle=True)\n",
    "\n",
    "\n",
    "print(\"[LOG] - Making class objects.\")\n",
    "MNISTGraph_model_train_100 = NMNISTGraphDataset(tonic_raw_dataset=ds_train, num_of_graph_events=NUM_OF_GRAPH_EVENTS,\n",
    "                                      R=R, Dmax=D_MAX,\n",
    "                                      noise_remove=NOICE_REMOVED, normalized_feat=NORMALIZE_FEAT,\n",
    "                                      nr_bin_xy_size=NR_BIN_XY_SIZE, nr_minimum_events=NR_MINIMUM_EVENTS,\n",
    "                                      nr_time_bin_size=NR_TIME_BIN_SIZE)\n",
    "\n",
    "MNISTGraph_model_test_100 = NMNISTGraphDataset(tonic_raw_dataset=ds_test, num_of_graph_events=NUM_OF_GRAPH_EVENTS,\n",
    "                                      R=R, Dmax=D_MAX,\n",
    "                                      noise_remove=NOICE_REMOVED, normalized_feat=NORMALIZE_FEAT,\n",
    "                                      nr_bin_xy_size=NR_BIN_XY_SIZE, nr_minimum_events=NR_MINIMUM_EVENTS,\n",
    "                                      nr_time_bin_size=NR_TIME_BIN_SIZE)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "MNISTGraph_model_test_50 = NMNISTGraphDataset(tonic_raw_dataset=ds_test, num_of_graph_events=50,\n",
    "                                            R=R, Dmax=D_MAX,\n",
    "                                            noise_remove=NOICE_REMOVED, normalized_feat=NORMALIZE_FEAT,\n",
    "                                            nr_bin_xy_size=NR_BIN_XY_SIZE, nr_minimum_events=NR_MINIMUM_EVENTS,\n",
    "                                            nr_time_bin_size=NR_TIME_BIN_SIZE)\n",
    "\n",
    "MNISTGraph_model_test_10 = NMNISTGraphDataset(tonic_raw_dataset=ds_test, num_of_graph_events=10,\n",
    "                                            R=R, Dmax=D_MAX,\n",
    "                                            noise_remove=NOICE_REMOVED, normalized_feat=NORMALIZE_FEAT,\n",
    "                                            nr_bin_xy_size=NR_BIN_XY_SIZE, nr_minimum_events=NR_MINIMUM_EVENTS,\n",
    "                                            nr_time_bin_size=NR_TIME_BIN_SIZE)\n",
    "\n",
    "HV_Dimensions = [5000, 7000]\n",
    "for item in HV_Dimensions:\n",
    "    HV_DIMENTION = item\n",
    "    gvfa_model = GraphCNN(input_dim=HV_DIMENTION, num_layers=LAYERS, delta=DELTA, graph_pooling_type=\"sum\",\n",
    "                          neighbor_pooling_type=\"sum\", device=DEVICE, equation=EQUATION).to(DEVICE)\n",
    "    cb = CodeBook(dim=HV_DIMENTION, x_max=X_MAX, y_max=Y_MAX, t_max=T_MAX, t_step=T_STEP)\n",
    "    hvs = HVs(codebook=cb, gvfa_model=gvfa_model)\n",
    "\n",
    "\n",
    "    X_train_100, X_test_100, X_test_50,X_test_10, Y_train_100,Y_test_100, y_test_50_10 = [],[],[],[], [],[],[]\n",
    "    print(\"[LOG] - Loading graph and converting to HVs.\")\n",
    "    for i in range(len(ds_train)):\n",
    "        # print(i)\n",
    "        g = MNISTGraph_model_train_100.get(i)\n",
    "        x, y = hvs.make_hvs(graph=g)\n",
    "        X_train_100.append(x)\n",
    "        Y_train_100.append(y)\n",
    "    for i in range(len(ds_test)):\n",
    "        # print(i)\n",
    "        g = MNISTGraph_model_test_100.get(i)\n",
    "        x, y = hvs.make_hvs(graph=g)\n",
    "        X_test_100.append(x)\n",
    "        Y_test_100.append(y)\n",
    "\n",
    "    # scaler = StandardScaler()\n",
    "    # X_train = scaler.fit_transform(X_train_)\n",
    "    # X_test = scaler.fit_transform(X_test_)\n",
    "\n",
    "    for i in range(len(ds_test)):\n",
    "        # print(i)\n",
    "        g_50 = MNISTGraph_model_test_50.get(i)\n",
    "        g_10 = MNISTGraph_model_test_10.get(i)\n",
    "\n",
    "        # print(g)\n",
    "\n",
    "        x_50, y = hvs.make_hvs(graph=g_50)\n",
    "        x_10, _ = hvs.make_hvs(graph=g_10)\n",
    "\n",
    "\n",
    "        X_test_50.append(x_50)\n",
    "        X_test_10.append(x_10)\n",
    "        y_test_50_10.append(y)\n",
    "\n",
    "\n",
    "    # X_test_50 = scaler.fit_transform(X_test_50_)\n",
    "    # X_test_10 = scaler.fit_transform(X_test_10_)\n",
    "\n",
    "\n",
    "    del cb\n",
    "    del hvs\n",
    "    del gvfa_model\n",
    "    # del full_ev_ds\n",
    "\n",
    "\n",
    "    print(\"[LOG] - Classification.\")\n",
    "\n",
    "    # clf = SVC(kernel=\"rbf\", C=0.1, gamma=0.9,degree=6)\n",
    "    pipe_xgb = Pipeline([\n",
    "        (\"scaler\", StandardScaler(with_mean=False)),\n",
    "        (\"xgb\", XGBClassifier(\n",
    "            objective=\"multi:softmax\",  # or \"multi:softprob\" for probability output\n",
    "            use_label_encoder=False,\n",
    "            eval_metric=\"mlogloss\"\n",
    "        ))\n",
    "    ])\n",
    "\n",
    "    # Define parameter grid for GridSearchCV\n",
    "    param_grid = {\n",
    "        \"xgb__n_estimators\": [50, 100],\n",
    "        \"xgb__max_depth\": [3, 6, 10],\n",
    "        \"xgb__learning_rate\": [0.01, 0.1, 0.2],\n",
    "        \"xgb__subsample\": [0.8, 1.0],\n",
    "        \"xgb__colsample_bytree\": [0.8, 1.0]\n",
    "    }\n",
    "\n",
    "    # Define grid search\n",
    "    grid = GridSearchCV(\n",
    "        pipe_xgb,\n",
    "        param_grid=param_grid,\n",
    "        cv=5,\n",
    "        scoring=\"accuracy\",\n",
    "        n_jobs=-1,\n",
    "        verbose=1\n",
    "    )\n",
    "    grid.fit(X_train_100, Y_train_100)\n",
    "\n",
    "    print(grid.best_params_)\n",
    "    print(grid.best_score_)\n",
    "    print(grid.param_grid)\n",
    "\n",
    "    print(\"----100------\")\n",
    "    print(f\"Train accuracy: {accuracy_score(Y_train_100, grid.predict(X_train_100)) * 100:.2f}%\")\n",
    "    print(f\"Test  accuracy: {accuracy_score(Y_test_100, grid.predict(X_test_100)) * 100:.2f}%\")\n",
    "\n",
    "    print(\"----50------\")\n",
    "    print(f\"Test  accuracy: {accuracy_score(y_test_50_10, grid.predict(X_test_50)) * 100:.2f}%\")\n",
    "\n",
    "    print(\"----10------\")\n",
    "    print(f\"Test  accuracy: {accuracy_score(y_test_50_10, grid.predict(X_test_10)) * 100:.2f}%\")\n",
    "\n",
    "    print(\"[LOG]- NUM_OF_GRAPH_EVENTS:\", NUM_OF_GRAPH_EVENTS, \" | DATASET:\", DATASET,\n",
    "          \" | NORMALIZE_FEAT:\", NORMALIZE_FEAT,\n",
    "          \" | R:\", R, \" | D_MAX: \", D_MAX, \" | NOICE_REMOVED: \", NOICE_REMOVED,\n",
    "          \" | NR_BIN_XY_SIZE: \", NR_BIN_XY_SIZE, \" | NR_TIME_BIN_SIZE: \", NR_TIME_BIN_SIZE, \" | NR_MINIMUM_EVENTS: \",\n",
    "          NR_MINIMUM_EVENTS, \" | HV_DIMENTION: \", HV_DIMENTION,\" | LAYERS: \", LAYERS,\" | DELTA: \", DELTA,\" | EQUATION: \", EQUATION,)\n",
    "\n",
    "        # del clf\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] - parameter initialization.\n",
      "[LOG] - Loading events\n",
      "[LOG] - Making class objects.\n",
      "[LOG] - Loading graph and converting to HVs.\n",
      "[LOG] - Classification.\n",
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[3], line 171\u001B[0m\n\u001B[0;32m    162\u001B[0m \u001B[38;5;66;03m# Define grid search\u001B[39;00m\n\u001B[0;32m    163\u001B[0m grid \u001B[38;5;241m=\u001B[39m GridSearchCV(\n\u001B[0;32m    164\u001B[0m     pipe_xgb,\n\u001B[0;32m    165\u001B[0m     param_grid\u001B[38;5;241m=\u001B[39mparam_grid,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    169\u001B[0m     verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    170\u001B[0m )\n\u001B[1;32m--> 171\u001B[0m \u001B[43mgrid\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train_100\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mY_train_100\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    173\u001B[0m \u001B[38;5;28mprint\u001B[39m(grid\u001B[38;5;241m.\u001B[39mbest_params_)\n\u001B[0;32m    174\u001B[0m \u001B[38;5;28mprint\u001B[39m(grid\u001B[38;5;241m.\u001B[39mbest_score_)\n",
      "File \u001B[1;32m~\\.conda\\envs\\efvoxel\\lib\\site-packages\\sklearn\\base.py:1389\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[1;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1382\u001B[0m     estimator\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[0;32m   1384\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[0;32m   1385\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[0;32m   1386\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[0;32m   1387\u001B[0m     )\n\u001B[0;32m   1388\u001B[0m ):\n\u001B[1;32m-> 1389\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fit_method(estimator, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\.conda\\envs\\efvoxel\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1024\u001B[0m, in \u001B[0;36mBaseSearchCV.fit\u001B[1;34m(self, X, y, **params)\u001B[0m\n\u001B[0;32m   1018\u001B[0m     results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_format_results(\n\u001B[0;32m   1019\u001B[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001B[0;32m   1020\u001B[0m     )\n\u001B[0;32m   1022\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m results\n\u001B[1;32m-> 1024\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_search\u001B[49m\u001B[43m(\u001B[49m\u001B[43mevaluate_candidates\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1026\u001B[0m \u001B[38;5;66;03m# multimetric is determined here because in the case of a callable\u001B[39;00m\n\u001B[0;32m   1027\u001B[0m \u001B[38;5;66;03m# self.scoring the return type is only known after calling\u001B[39;00m\n\u001B[0;32m   1028\u001B[0m first_test_score \u001B[38;5;241m=\u001B[39m all_out[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest_scores\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[1;32m~\\.conda\\envs\\efvoxel\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1571\u001B[0m, in \u001B[0;36mGridSearchCV._run_search\u001B[1;34m(self, evaluate_candidates)\u001B[0m\n\u001B[0;32m   1569\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m_run_search\u001B[39m(\u001B[38;5;28mself\u001B[39m, evaluate_candidates):\n\u001B[0;32m   1570\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001B[39;00m\n\u001B[1;32m-> 1571\u001B[0m     \u001B[43mevaluate_candidates\u001B[49m\u001B[43m(\u001B[49m\u001B[43mParameterGrid\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparam_grid\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.conda\\envs\\efvoxel\\lib\\site-packages\\sklearn\\model_selection\\_search.py:970\u001B[0m, in \u001B[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001B[1;34m(candidate_params, cv, more_results)\u001B[0m\n\u001B[0;32m    962\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m    963\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\n\u001B[0;32m    964\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFitting \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;124m folds for each of \u001B[39m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;124m candidates,\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    965\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m totalling \u001B[39m\u001B[38;5;132;01m{2}\u001B[39;00m\u001B[38;5;124m fits\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[0;32m    966\u001B[0m             n_splits, n_candidates, n_candidates \u001B[38;5;241m*\u001B[39m n_splits\n\u001B[0;32m    967\u001B[0m         )\n\u001B[0;32m    968\u001B[0m     )\n\u001B[1;32m--> 970\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[43mparallel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    971\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdelayed\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_fit_and_score\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    972\u001B[0m \u001B[43m        \u001B[49m\u001B[43mclone\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbase_estimator\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    973\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    974\u001B[0m \u001B[43m        \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    975\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrain\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    976\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtest\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtest\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    977\u001B[0m \u001B[43m        \u001B[49m\u001B[43mparameters\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparameters\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    978\u001B[0m \u001B[43m        \u001B[49m\u001B[43msplit_progress\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43msplit_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_splits\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    979\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcandidate_progress\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcand_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_candidates\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    980\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfit_and_score_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    981\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    982\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mcand_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparameters\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43msplit_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mproduct\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    983\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcandidate_params\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    984\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msplit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mrouted_params\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msplitter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msplit\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    985\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    986\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    988\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(out) \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m    989\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    990\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNo fits were performed. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    991\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWas the CV iterator empty? \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    992\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWere there no candidates?\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    993\u001B[0m     )\n",
      "File \u001B[1;32m~\\.conda\\envs\\efvoxel\\lib\\site-packages\\sklearn\\utils\\parallel.py:77\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m     72\u001B[0m config \u001B[38;5;241m=\u001B[39m get_config()\n\u001B[0;32m     73\u001B[0m iterable_with_config \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m     74\u001B[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001B[0;32m     75\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m delayed_func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m iterable\n\u001B[0;32m     76\u001B[0m )\n\u001B[1;32m---> 77\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__call__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43miterable_with_config\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.conda\\envs\\efvoxel\\lib\\site-packages\\joblib\\parallel.py:2007\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m   2001\u001B[0m \u001B[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001B[39;00m\n\u001B[0;32m   2002\u001B[0m \u001B[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001B[39;00m\n\u001B[0;32m   2003\u001B[0m \u001B[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001B[39;00m\n\u001B[0;32m   2004\u001B[0m \u001B[38;5;66;03m# dispatch of the tasks to the workers.\u001B[39;00m\n\u001B[0;32m   2005\u001B[0m \u001B[38;5;28mnext\u001B[39m(output)\n\u001B[1;32m-> 2007\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m output \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreturn_generator \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43moutput\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.conda\\envs\\efvoxel\\lib\\site-packages\\joblib\\parallel.py:1650\u001B[0m, in \u001B[0;36mParallel._get_outputs\u001B[1;34m(self, iterator, pre_dispatch)\u001B[0m\n\u001B[0;32m   1647\u001B[0m     \u001B[38;5;28;01myield\u001B[39;00m\n\u001B[0;32m   1649\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend\u001B[38;5;241m.\u001B[39mretrieval_context():\n\u001B[1;32m-> 1650\u001B[0m         \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_retrieve()\n\u001B[0;32m   1652\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mGeneratorExit\u001B[39;00m:\n\u001B[0;32m   1653\u001B[0m     \u001B[38;5;66;03m# The generator has been garbage collected before being fully\u001B[39;00m\n\u001B[0;32m   1654\u001B[0m     \u001B[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001B[39;00m\n\u001B[0;32m   1655\u001B[0m     \u001B[38;5;66;03m# the user if necessary.\u001B[39;00m\n\u001B[0;32m   1656\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_exception \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[1;32m~\\.conda\\envs\\efvoxel\\lib\\site-packages\\joblib\\parallel.py:1762\u001B[0m, in \u001B[0;36mParallel._retrieve\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1757\u001B[0m \u001B[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001B[39;00m\n\u001B[0;32m   1758\u001B[0m \u001B[38;5;66;03m# async callbacks to progress.\u001B[39;00m\n\u001B[0;32m   1759\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m ((\u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jobs) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m\n\u001B[0;32m   1760\u001B[0m     (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jobs[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mget_status(\n\u001B[0;32m   1761\u001B[0m         timeout\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtimeout) \u001B[38;5;241m==\u001B[39m TASK_PENDING)):\n\u001B[1;32m-> 1762\u001B[0m     \u001B[43mtime\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0.01\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1763\u001B[0m     \u001B[38;5;28;01mcontinue\u001B[39;00m\n\u001B[0;32m   1765\u001B[0m \u001B[38;5;66;03m# We need to be careful: the job list can be filling up as\u001B[39;00m\n\u001B[0;32m   1766\u001B[0m \u001B[38;5;66;03m# we empty it and Python list are not thread-safe by\u001B[39;00m\n\u001B[0;32m   1767\u001B[0m \u001B[38;5;66;03m# default hence the use of the lock\u001B[39;00m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 3
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
